---
- name: 校验删除 master 节点数量
  run_once: true
  ansible.builtin.assert:
    that: (groups['delete_masters'] | unique)|length > 0
    msg: " 未配置删除 master 节点!"

- name: 校验将被移除的 master 节点是否在原 master 组中
  run_once: true
  ansible.builtin.assert:
    that: "{{ item in groups['kube_masters'] }}"
    msg: "当前节点: {{ item }}, 并未在 kube_masters 组中, 不需要进行移除操作。"
  with_items: "{{ groups['delete_masters'] }}"

- name: 校验现有 master 节点数量
  run_once: true
  ansible.builtin.assert:
    that: groups['kube_masters'] | difference(groups['delete_masters']) | unique | length >= 1
    msg: "移除 master 节点后, 至少保证有一个 master 节点运行才可进行 master 节点移除操作。"

- name: 校验移除 master 节点后剩余 master 节点数量
  run_once: true
  ansible.builtin.assert:
    that: groups['kube_masters'] | difference(groups['delete_masters']) | unique | length is odd
    msg: "移除 master 节点后, 剩余 master 节点只能为奇数个, 当前 {{ groups['kube_masters'] | difference(groups['delete_masters']) | unique | length }} 个, 请修改 master 节点数量至奇数个。"

- name: 刷新集群 master 节点状态
  failed_when: false
  changed_when: true
  ansible.builtin.command: >
    kubeadm reset phase update-cluster-status
    kubeadm upgrade node phase kubelet-config

- name: 删除 master 节点组件相关文件
  ansible.builtin.file:
    name: "{{ item }}"
    state: absent
  with_items:
  - "{{ k8s_pki_dir }}"
  - "{{ manifest_dir }}/kube-apiserver.yaml"
  - "{{ manifest_dir }}/kube-scheduler.yaml"
  - "{{ manifest_dir }}/kube-controller-manager.yaml"
  - "{{ kubernetes_etc_dir }}/admin.conf"
  - "{{ kubernetes_etc_dir }}/controller-manager.conf"
  - "{{ kubernetes_etc_dir }}/scheduler.conf"
  - "{{ kubernetes_etc_dir }}/audit"
  - "{{ kubernetes_log_dir }}/audit"
  - "{{ kubernetes_log_dir }}/kube-apiserver"
  - "{{ kubernetes_log_dir }}/kube-controller-manager"
  - "{{ kubernetes_log_dir }}/kube-scheduler"
  - "{{ ansible_env.HOME }}/.kube/config"

- name: 取消节点原有 master 角色标签
  failed_when: false
  changed_when: true
  ansible.builtin.shell: >
    kubectl label nodes {{ inventory_hostname }} node-role.kubernetes.io/control-plane='' --overwrite;
    kubectl label nodes {{ inventory_hostname }} node-role.kubernetes.io/master='' --overwrite;
    kubectl label nodes {{ inventory_hostname }} node-role.kubernetes.io/control-plane-;
    kubectl label nodes {{ inventory_hostname }} node-role.kubernetes.io/master-;
    kubectl label nodes {{ inventory_hostname }} node-role.kubernetes.io/ingress-
  delegate_to: "{{ (groups['kube_masters'] | difference(groups['delete_masters']) | unique | first) }}"

- name: 取消 master 节点 taint, 使 master 节点可以调度
  failed_when: false
  changed_when: true
  ansible.builtin.shell: >
    kubectl taint nodes {{ inventory_hostname }} node-role.kubernetes.io/master='':NoSchedule --overwrite;
    kubectl taint nodes {{ inventory_hostname }} node-role.kubernetes.io/master-;
    kubectl uncordon {{ inventory_hostname }}
  delegate_to: "{{ (groups['kube_masters'] | difference(groups['delete_masters']) | unique | first) }}"

- name: 添加 worker 角色标签
  failed_when: false
  changed_when: true
  ansible.builtin.shell: >
    kubectl label nodes {{ inventory_hostname }} node-role.kubernetes.io/worker='' --overwrite
  delegate_to: "{{ (groups['kube_masters'] | difference(groups['delete_masters']) | unique | first) }}"

- name: 获取 kubernetes ca 证书
  ansible.builtin.slurp:
    src: "{{ item }}"
  with_items:
  - "{{ kubernetes_ca }}"
  register: slurp_kubernetes_ca_cert
  run_once: true
  delegate_to: "{{ (groups['kube_masters'] | difference(groups['delete_masters']) | unique | first) }}"

- name: 恢复目录
  ansible.builtin.file:
    path: "{{ item }}"
    state: directory
    mode: 0644
  with_items:
  - "{{ k8s_pki_dir }}"

- name: 恢复 kubernetes ca 证书
  ansible.builtin.copy:
    dest: "{{ item.source }}"
    content: "{{ item.content | b64decode }}"
    owner: root
    group: root
    mode: 0644
  no_log: true
  with_items: "{{ slurp_kubernetes_ca_cert.results }}"

- name: 重启 kubelet 服务
  ansible.builtin.systemd:
    name: kubelet
    daemon_reload: yes
    state: restarted
    enabled: yes
  register: started_kubelet
  until: started_kubelet.status.ActiveState == "active"
  retries: 3
  delay: "{{ retry_stagger }}"
